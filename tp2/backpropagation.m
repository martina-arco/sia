%Algoritmo de Entrenamiento de BACKPROPAGATION para Redes Neuronalesfunction learn = backpropagation(XE, S, D, L, rate, alfa, dmse)    mse = Inf;                  %Asumiendo Pesos Iniciales Malos    epoch = 1;                  %Rango de valores iniciales [-1 1]    [N, P] = size(XE);           %Numero de Patrones P y Entradas N        X = ones(21, P) * -1;    X(2:21, :) = XE(1:20, :)        [N, P] = size(X);            [Q, P] = size(D);           %Numero de Patrones P y Salidas Q     depth = 3;                  %Profundidad de la red (nro capas)        delta = cell(depth, 1);    delta{1} = [0 0];    delta{2} = [0 0 0];    delta{3} = [0 0];      %Inicializar Matriz de Pesos para cada capa en el rango [-1,1]  W = 2.*rand(depth, N) - 1            %Pre-alocacion de la matriz de pesos  %Inicializar Matrices de los delta-pesos de ajuste  dW = zeros(1, depth - 1)               %Pre-alocacion de los delta pesos  %Inicializar los campos locales inducidos 'v'  v = ones(1, depth)                %Pre-alocacion de los campos locales  %Inicializar las salidas 'y' de cada capa  y = ones(1, depth-1)             %Pre-alocacion de las salidas locales  %% 2. Calculo Forward y Backward para cada epoch  while (mse > dmse) && (epoch <= 10000)      e = zeros(Q, P);      err = zeros(1, P);            for p = 1:P          %Calculo Forward capa-por-capa para cada patron p          v{1}(1 : end - 1) = X(:, p);                    for i = 1 : depth - 1              y{i} = W{i} * v{i};                             if i < depth - 1                  v{i+1}(1 : end-1) = tansig(y{i}); %Calculo de la salida con tangente hiperbolica              else                  v{i+1} = tansig(y{i});          %Calculo de la salida              end          end                    %Calculo de la seÃ±al de error          e(:, p) = D(:, p) - v{end};                    %Calculo de la energia del error          if size(D, 1) == 1              err(1, p) = 0.5 * (e(:, p).^2);          elseif size(D, 1) > 1              err(1, p) = 0.5 * sum(e(:, p).^2);          end                    %Calculo Backward capa-por-capa para cada patron p                  delta = e(:, p).*(tansig('dn', y{end}));                    %Ajuste de pesos          for i = depth-1 : -1 : 1                               dW{i} = rate * delta * v{i}' + alfa.*dW{i};              W{i} = W{i} + dW{i};                            if i > 1                  delta = tansig('dn', y{i-1}).* (delta' * W{i}(:, 1 : end - 1))';              end          end                end            %Calculo del mean square error      mse = (1 / P) * sum(err);      epoch = epoch + 1;      hold on      figure(2)      semilogx(epoch, mse, 'ro')      hold off  end  learn.pesos = W;  learn.epocas = epoch;  learn.estructura = L;  learn.error = mse;endfunction